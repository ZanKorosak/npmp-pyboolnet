rmae(test$quality, predicted, mean(train$quality))
rf.model <- randomForest(quality ~ ., train)
library(randomForest)
install.packages('RandomForest')
install.packages('randomForest')
rf.model <- randomForest(quality ~ ., train)
library(randomForest)
rf.model <- randomForest(quality ~ ., train)
predicted <- predict(rf.model, test)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
library(e1071)
svm.model <- svm(quality ~ ., train)
predicted <- predict(svm.model, test)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
library(kknn)
knn.model <- kknn(quality ~ ., train, test, k = 5)
predicted <- fitted(knn.model)
library(kknn)
install.packages('kknn')
library(kknn)
knn.model <- kknn(quality ~ ., train, test, k = 5)
predicted <- fitted(knn.model)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
library(nnet)
set.seed(0)
nn.model <- nnet(quality ~ ., train, size = 5, decay = 0.0001, maxit = 10000, linout = T)
predicted <- predict(nn.model, test)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
min_vals <- apply(train[,1:11], 2, min)
max_vals <- apply(train[,1:11], 2, max)
normTrain <- as.data.frame(scale(train[,1:11], center = min_vals, scale = max_vals - min_vals))
normTrain$quality <- train$quality
?apply
min_vals <- apply(train[,1:11], 2, min)
max_vals <- apply(train[,1:11], 2, max)
min_vals
normTrain <- as.data.frame(scale(train[,1:11], center = min_vals, scale = max_vals - min_vals))
normTrain$quality <- train$quality
# na enak nacin (z istimi mejnimi vrednostmi!) normaliziramo tudi testno mnozico
normTest <- as.data.frame(scale(test[,1:11], center = min_vals, scale = max_vals - min_vals))
normTest$quality <- test$quality
set.seed(0)
nn.model <- nnet(quality ~ ., normTrain, size = 5, decay = 0.0001, maxit = 10000, linout = T)
predicted <- predict(nn.model, normTest)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
nn.model <- nnet(quality ~ ., normTrain, size = 10, decay = 0.0001, maxit = 10000, linout = T)
predicted <- predict(nn.model, normTest)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
nn.model <- nnet(quality ~ ., normTrain, size = 7, decay = 0.0001, maxit = 10000, linout = T)
predicted <- predict(nn.model, normTest)
mae(test$quality, predicted)
rmae(test$quality, predicted, mean(train$quality))
data <- read.table("spambase.txt", header = T, sep=",")
summary(data)
data$is_spam <- as.factor(data$is_spam)
set.seed(0)
sel <- sample(1:nrow(data), as.integer(nrow(data) * 0.7), F)
train <- data[sel,]
test <- data[-sel,]
# ciljna spremenljivka je atribut "is_spam" (58. stolpec)
observed <- test$is_spam
library(nnet)
obsMat <- class.ind(test$is_spam)
CA <- function(observed, predicted)
{
tab <- table(observed, predicted)
sum(diag(tab)) / sum(tab)
}
brier.score <- function(observedMatrix, predictedMatrix)
{
sum((observedMatrix - predictedMatrix) ^ 2) / nrow(predictedMatrix)
}
library(rpart)
dt <- rpart(is_spam ~ ., data = train)
predicted <- predict(dt, test, type="class")
CA(observed, predicted)
predMat <- predict(dt, test, type = "prob")
brier.score(obsMat, predMat)
library(CORElearn)
cm.dt <- CoreModel(is_spam ~ ., data = train, model="tree")
predicted <- predict(cm.dt, test, type="class")
install.packages('CoreModel')
library(CORElearn)
cm.dt <- CoreModel(is_spam ~ ., data = train, model="tree")
predicted <- predict(cm.dt, test, type="class")
library(CORElearn)
install.packages('CORElearn')
library(CORElearn)
cm.dt <- CoreModel(is_spam ~ ., data = train, model="tree")
predicted <- predict(cm.dt, test, type="class")
CA(observed, predicted)
predMat <- predict(cm.dt, test, type = "prob")
brier.score(obsMat, predMat)
library(e1071)
nb <- naiveBayes(is_spam ~ ., data = train)
predicted <- predict(nb, test, type="class")
CA(observed, predicted)
predMat <- predict(nb, test, type = "raw")
brier.score(obsMat, predMat)
library(CORElearn)
cm.nb <- CoreModel(is_spam ~ ., data = train, model="bayes")
predicted <- predict(cm.nb, test, type="class")
CA(observed, predicted)
library(CORElearn)
cm.knn <- CoreModel(is_spam ~ ., data = train, model="knn", kInNN = 5)
predicted <- predict(cm.knn, test, type="class")
CA(observed, predicted)
predMat <- predict(cm.knn, test, type = "probability")
brier.score(obsMat, predMat)
library(randomForest)
rf <- randomForest(is_spam ~ ., data = train)
predicted <- predict(rf, test, type="class")
CA(observed, predicted)
predMat <- predict(rf, test, type = "prob")
brier.score(obsMat, predMat)
library(CORElearn)
cm.rf <- CoreModel(is_spam ~ ., data = train, model="rf")
predicted <- predict(cm.rf, test, type="class")
CA(observed, predicted)
predMat <- predict(cm.rf, test, type = "probability")
brier.score(obsMat, predMat)
library(e1071)
sm <- svm(is_spam ~ ., data = train)
predicted <- predict(sm, test, type="class")
CA(observed, predicted)
sm <- svm(is_spam ~ ., train, probability = T)
pred <- predict(sm, test, probability = T)
predMat <- attr(pred, "probabilities")
# v tem konkretnem primeru, vrstni red razredov (stolpcev) v matriki predMat je
# obraten kot v matriki obsMat.
colnames(obsMat)
colnames(predMat)
# Iz tega razloga zamenjemo vrstni red stolpcev v matriki predMat
brier.score(obsMat, predMat[,c(2,1)])
library(kernlab)
model.svm <- ksvm(is_spam ~ ., data = train, kernel = "rbfdot")
install.packages('kernlab')
library(kernlab)
model.svm <- ksvm(is_spam ~ ., data = train, kernel = "rbfdot")
predicted <- predict(model.svm, test, type = "response")
CA(observed, predicted)
model.svm <- ksvm(is_spam ~ ., data = train, kernel = "rbfdot", prob.model = T)
predMat <- predict(model.svm, test, type = "prob")
brier.score(obsMat, predMat)
library(nnet)
# poiscemo zalogo vrednosti zveznih atributov
# (v nasem primeru so vsi atributi zvezni, razen ciljne spr. "is_spam", ki je 58. stolpec)
max_train <- apply(train[,-58], 2, max)
min_train <- apply(train[,-58], 2, min)
# normaliziramo podatke
train_scaled <- scale(train[,-58], center = min_train, scale = max_train - min_train)
train_scaled <- data.frame(train_scaled)
train_scaled$is_spam <- train$is_spam
# vse vrednosti atributov v ucni mnozici so na intervalu [0,1]
summary(train_scaled)
# testno mnozico skaliramo na zalogo vrednosti iz ucne mnozice!
test_scaled <- scale(test[,-58], center = min_train, scale = max_train - min_train)
test_scaled <- data.frame(test_scaled)
test_scaled$is_spam <- test$is_spam
# v testni mnozici ne bodo vse vrednosti na intervalu [0,1]!
summary(test_scaled)
set.seed(0)
nn <- nnet(is_spam ~ ., data = train_scaled, size = 5, decay = 0.0001, maxit = 10000)
predicted <- predict(nn, test_scaled, type = "class")
CA(observed, predicted)
pm <- predict(nn, test_scaled, type = "raw")
predMat <- cbind(1-pm, pm)
brier.score(obsMat, predMat)
###############################################################################################################
#
# - nalozite podatke iz datoteke "auto-mpg.txt"
#
cars <- read.table("auto-mpg.txt", sep=",", header=T)
summary(cars)
plot(cars$horsepower ~ cars$displacement)
data("Groceries")
#######################################################################################################################
#
# PROBLEMS
#
#######################################################################################################################
#
# - Use Apriori algorithm to discove interesting relations between variables in given datasets:
#
library(arules)
install.packages(arules)
install.packages("arules")
#######################################################################################################################
#
# PROBLEMS
#
#######################################################################################################################
#
# - Use Apriori algorithm to discove interesting relations between variables in given datasets:
#
library(arules)
data("Groceries")
summary(Groceries)
data("AdultUC1")
data("AdultUCI")
summary(Groceries)
data= data("AdultUCI")
summary(data)
library(arules)
# load a built-in dataset
data("AdultUCI")
head(AdultUCI)
# remove the continuous attribute "fnlwgt" (final weight)
AdultUCI$fnlwgt <- NULL
# remove the continuous attribute "education-num" because it is just a numeric representation of the attribute "education"
AdultUCI$"education-num" <- NULL
hist(AdultUCI$age)
abline(v=c(25,45,65),col="red")
AdultUCI$"age" <- factor(
cut(AdultUCI$age, c(0, 25, 45, 65, 100)),
labels = c("Young", "Middle-aged", "Senior", "Old"),
ordered = TRUE)
hist(AdultUCI$"hours-per-week")
abline(v=c(25,40,60),col="red")
AdultUCI$"hours-per-week" <- factor(
cut(AdultUCI$"hours-per-week", c(0, 25, 40, 60, 168)),
labels = c("Part-time", "Full-time", "Over-time", "Workaholic"),
ordered = TRUE)
hist(AdultUCI$"capital-gain")
with.gain <- AdultUCI$"capital-gain" > 0
median.gain <- median(AdultUCI$"capital-gain"[with.gain])
abline(v=median.gain,col="red")
AdultUCI$"capital-gain" <- factor(
cut(AdultUCI$"capital-gain", c(-Inf, 0, median.gain, Inf)),
labels = c("None", "Low", "High"),
ordered = TRUE)
hist(AdultUCI$"capital-loss")
with.loss <- AdultUCI$"capital-loss" > 0
median.loss <- median(AdultUCI$"capital-loss"[with.loss])
abline(v=median.loss,col="red")
AdultUCI$"capital-loss" <- factor(
cut(AdultUCI$"capital-loss", c(-Inf, 0, median.loss, Inf)),
labels = c("none", "low", "high"),
ordered = TRUE)
summary(AdultUCI)
head(AdultUCI)
# now we are ready to create transactions
Adult <- as(AdultUCI, "transactions")
Adult
# a transaction is a list of "items" in a single instance
AdultUCI[1,]
inspect(Adult[1,])
summary(Adult)
# plot item frequencies (with a minimum support of 20%)
itemFrequencyPlot(Adult, support = 0.2)
# find the rules with a minimum support of 1% and a confidence of 60%
rules <- apriori(Adult, parameter = list(support = 0.01, confidence = 0.6))
rules
summary(rules)
# inspect the ten rules with the highest support
inspect(sort(rules)[1:10])
# inspect the ten rules with the highest confidence
inspect(sort(rules, by = "confidence")[1:10])
rulesSubset <- subset(rules, subset = support > 0.1)
inspect(sort(rulesSubset, by = "confidence")[1:5])
# select all rules with item "income=small" in the right-hand-side and confidence > 0.7
rulesIncomeSmall <- subset(rules, subset = rhs %in% "income=small" & confidence > 0.7)
inspect(sort(rulesIncomeSmall, by = "confidence")[1:5])
length(rulesIncomeSmall)
redundantRules <- is.redundant(rulesIncomeSmall)
redundantRules
rulesIncomeSmall <- rulesIncomeSmall[!redundantRules]
inspect(rulesIncomeSmall)
# select itemsets matching any given item ("age=Young" OR "workclass=Private") in the left-hand side
rulesYoungPrivateLHS <- subset(rules, subset = lhs %in% c("age=Young", "workclass=Private"))
inspect(sort(rulesYoungPrivateLHS, by = "confidence")[1:5])
# select only itemsets matching all given items ("age=Young" AND "workclass=Private") in the left-hand side
rulesYoungPrivateLHS <- subset(rules, subset = lhs %ain% c("age=Young", "workclass=Private"))
inspect(sort(rulesYoungPrivateLHS, by = "confidence")[1:5])
#  partial matching
rulesIncomeLHS <- subset(rules, subset = lhs %pin% "income=")
inspect(sort(rulesIncomeLHS, by = "confidence")[1:5])
r <- subset(rules, subset = !(rhs %in% c("capital-gain=None","capital-loss=none")))
inspect(sort(r, by = "confidence")[1:5])
r <- subset(rules, subset = !(rhs %in% c("capital-gain=None","capital-loss=none", "sex=Male")))
inspect(sort(r, by = "confidence")[1:5])
r <- subset(rules, subset = !(rhs %in% c("capital-gain=None","capital-loss=none")))
inspect(sort(r, by = "confidence")[1:5])
r <- subset(rules, subset = lhs %in% "sex=Female" & rhs %pin% "hours-per-week=")
inspect(sort(r, by = "confidence")[1:5])
# size returns the sum of the number of elements in the LHS and the RHS
r <- rules[size(rules)==2]
inspect(sort(r, by = "confidence")[1:5])
# install.packages(c("viridisLite", "arulesViz"))
library(arulesViz)
install.packages('arulesViz')
# install.packages(c("viridisLite", "arulesViz"))
library(arulesViz)
# a scatter plot using support and confidence on the axes. In addition a third measure (default: lift)
# is used as the color
plot(rules)
vehicle <- read.table("vehicle.txt", sep=",", header=T, stringsAsFactors=T)
summary(vehicle)
source("evalAttr.R")
source("evalAttr.R")
data <- vehicle
for (i in 1:ncol(data))
if (is.numeric(data[,i]))
data[,i] <- disc.mdlp(data[,i], data$Class)
summary(data)
set.seed(0)
sel <- sample(1:nrow(data), round(nrow(data) * 0.7), replace=F)
train <- data[sel,]
test <- data[-sel,]
source("naiveBayes.R")
nb <- nBayes(Class ~ ., train, m=2)
nb
predicted <- predict(nb, test, type="class")
ct <- table(test$Class, predicted)
ct
sum(diag(ct))/sum(ct)
nb$prior
ct
sum(diag(ct))/sum(ct)
snb <- semiNB(Class ~ ., train, m=2, th=0.5)
names(snb)
snb$prior
head(snb$merge)
length(snb$merge)
snb$prior
head(snb$merge)
length(snb$merge)
predicted <- predict(snb, test, type="class")
ct <- table(test$Class, predicted)
ct
sum(diag(ct))/sum(ct)
# install.packages("bnlearn")
library(bnlearn)
install.packages("bnlearn")
# install.packages("bnlearn")
library(bnlearn)
tan.dag <- tree.bayes(train, training="Class")
plot(tan.dag)
fit.tan <- bn.fit(tan.dag, train, method = "bayes")
predicted <- predict(fit.tan, test)
ct <- table(test$Class, predicted)
ct
sum(diag(ct))/sum(ct)
bus.dag <- empty.graph(nodes = c("Rezim", "Linija", "Bus", "Smer"))
bus.dag <- set.arc(bus.dag, from = "Rezim", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Smer")
plot(bus.dag)
bus.dag <- set.arc(bus.dag, from = "Rezim", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Smer")
plot(bus.dag)
bus.dag <- empty.graph(nodes = c("Rezim", "Linija", "Bus", "Smer"))
plot(bus.dag)
bus.dag <- set.arc(bus.dag, from = "Rezim", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Bus")
bus.dag <- set.arc(bus.dag, from = "Linija", to = "Smer")
plot(bus.dag)
Rezim.oznake <- c("nocni", "dnevni")
Linija.oznake <- c("L1", "L2", "L3")
Bus.oznake <- c("kratek", "dolg")
Smer.oznake <- c("stadion", "zelezniska", "garaza")
Rezim.prob <- array(c(1/3, 2/3),
dim = 2,
dimnames = list(Rezim = Rezim.oznake))
Rezim.prob
Linija.prob <- array(c(2/10, 5/10, 3/10),
dim = 3,
dimnames = list(Linja = Linija.oznake))
Linija.prob
Bus.prob <- array(c(1,0,9/10,1/10,1/10,9/10,0,1,1/5,4/5,1/5,4/5),
dim = c(2,2,3),
dimnames = list(Bus = Bus.oznake, Rezim = Rezim.oznake, Linija = Linija.oznake))
Bus.prob
Smer.prob <- array(c(0,9/10,1/10,0,9/10,1/10,9/10,0,1/10),
dim = c(3,3),
dimnames = list(Smer = Smer.oznake, Linija = Linija.oznake))
Smer.prob
bus.bn <- custom.fit(bus.dag, list(Rezim = Rezim.prob, Linija = Linija.prob, Bus = Bus.prob, Smer = Smer.prob))
bus.bn
samples <- rbn(bus.bn, n=5000)
head(samples)
table(samples$Rezim)/nrow(samples)
table(samples$Linija)/nrow(samples)
sel <- samples$Linija == "L1"
tab <- table(samples$Bus[sel], samples$Rezim[sel])
apply(tab, 2, function(x){x/sum(x)})
samples <- rbn(bus.bn, n=10000)
head(samples)
table(samples$Rezim)/nrow(samples)
table(samples$Linija)/nrow(samples)
sel <- samples$Linija == "L1"
tab <- table(samples$Bus[sel], samples$Rezim[sel])
apply(tab, 2, function(x){x/sum(x)})
# Ura je 22:00. Na postajo prihaja kratek avtobus. Kaksna je verjetnost, da vozi v smeri stadiona?
cpquery(bus.bn, event=(Smer=="stadion"), evidence=(Rezim=="nocni") & (Bus=="kratek"), n=10^6)
# Na postajaliscu stoji avtobus linije L2. Kaksna je verjetnost, da je vozilo dolgo?
cpquery(bus.bn, event=(Bus=="dolg"), evidence=(Linija=="L2"), n=10^6)
# Na postajalisce prihaja dolg avtobus. Kaksna je verjetnost, da je dnevni rezim delovanja?
cpquery(bus.bn, event=(Rezim=="dnevni"), evidence=(Bus=="dolg"), n=10^6)
# Na postajalisce prihaja kratek avtobus. Kaksna je verjetnost, da je dnevni rezim delovanja
# in da avtobus vozi v garazo?
cpquery(bus.bn, event=(Rezim=="dnevni") & (Smer=="garaza"), evidence=(Bus=="kratek"), n=10^6)
# Kaksna je verjetnost, da prihaja dolg avtobus?
cpquery(bus.bn, event=(Bus=="dolg"), evidence=TRUE, n=10^6)
data(coronary)
summary(coronary)
head(coronary)
# avtomatsko dolocimo strukturo mreze iz podatkov
bn.dag <- hc(coronary)
plot(bn.dag)
# avtomatsko dolocimo strukturo mreze iz podatkov
bn.dag <- hc(coronary)
plot(bn.dag)
plot(bn.dag)
# odstranimo dvisnost med vozliscema "M. Work" in "Family"
bn.dag <- drop.arc(bn.dag, from="M. Work", to="Family")
plot(bn.dag)
# dolocimo parametre pogojnih verjetnosti na podlagi strukture mreze in podatkov
fit.bn <- bn.fit(bn.dag, data = coronary)
fit.bn
cpquery(fit.bn, event = (Proteins == "<3"), evidence = (Smoking == "no"))
cpquery(fit.bn, event = (Proteins != "<3"), evidence = (Smoking == "no"))
cpquery(fit.bn, event = (Proteins == "<3"), evidence = (Smoking == "no" & Pressure == ">140"))
cpquery(fit.bn, event = (Pressure == ">140"), evidence = (Proteins == "<3"))
?cpquery
cpquery(fit.bn, event = (Proteins == "<3"), evidence = (Smoking == "no"), n=10^6)
cpquery(fit.bn, event = (Proteins != "<3"), evidence = (Smoking == "no"), n=10^6)
cpquery(fit.bn, event = (Proteins == "<3"), evidence = (Smoking == "no" & Pressure == ">140"), n=10^6)
cpquery(fit.bn, event = (Pressure == ">140"), evidence = (Proteins == "<3"), n=10^6)
data <- read.table("car.txt", sep=",", header=T, stringsAsFactors=T)
summary(data)
head(data)
set.seed(0)
sel <- sample(1:nrow(data), round(nrow(data)*0.7), replace=F)
train <- data[sel,]
test <- data[-sel,]
bn.dag <- empty.graph(nodes = names(train))
for (i in 1:6)
bn.dag <- set.arc(bn.dag, from = "class", to = names(train)[i])
plot(bn.dag)
fit.bn <- bn.fit(bn.dag, data = train)
predicted <- predict(fit.bn, node = "class", data = test, method="bayes-lw")
observed <- test$class
ct <- table(observed, predicted)
ct
sum(diag(ct))/sum(ct)
# na primer, izracun medsebojne informacije za atributa "maint" in "buying"
ci.test("maint", "buying", "class", train, test="mi-adf")
statinfo <- ci.test("maint", "buying", "class", train, test="mi-adf")
names(statinfo)
statinfo$statistic
statinfo$p.value
for (i in 1:5)
for (j in (i+1):6)
{
att1 <- names(train)[i]
att2 <- names(train)[j]
statinfo <- ci.test(att1, att2, "class", data=train, test="mi-adf")
print(paste(att1, "-", att2, ":", statinfo$statistic, "(", statinfo$p.value, ")"))
}
bn.dag <- set.arc(bn.dag, from = "maint", to = "buying")
bn.dag <- set.arc(bn.dag, from = "safety", to = "buying")
bn.dag <- set.arc(bn.dag, from = "safety", to = "persons")
bn.dag <- set.arc(bn.dag, from = "safety", to = "lug_boot")
plot(bn.dag)
fit.bn <- bn.fit(bn.dag, data = train)
predicted <- predict(fit.bn, node = "class", data = test, method="bayes-lw")
observed <- test$class
ct <- table(observed, predicted)
ct
sum(diag(ct))/sum(ct)
install.packages('boolnet')
install.packages('BoolNet')
workdir
dir
dir()
setwd('C:\Users\joksz\OneDrive\Documents\Faks\Magisterij\NPMP\Seminarska2\pyboolnet\data')
setwd('C:\\Users\joksz\OneDrive\Documents\Faks\Magisterij\NPMP\Seminarska2\pyboolnet\data')
setwd('C:\\Users\\joksz\\OneDrive\\Documents\\Faks\\Magisterij\\NPMP\\Seminarska2\\pyboolnet\\data')
wd
printwd
dir()
net = loadNetwork("Montagud2021_Prostate_Cancer.sbml")
net
net <- loadNetwork("Montagud2021_Prostate_Cancer.sbml")
data(net)
install.packages('BoolNet')
load('BoolNet')
library('BoolNet')
load('BoolNet')
net <- loadNetwork("Montagud2021_Prostate_Cancer.sbml")
net <- loadSBML("Montagud2021_Prostate_Cancer.sbml")
data(net)
net
saveNetwork(net, "Montagud2021_Prostate_Cancer.bnet")
file='Montagud2021_Prostate_Cancer'
net <- loadSBML(file + ".sbml")
file='Montagud2021_Prostate_Cancer'
net <- loadSBML(paste(file,".sbml"))
print(paste(file,".sbml"))
print(paste(file,".sbml", sep=""))
file='Montagud2021_Prostate_Cancer'
print(paste(file,".sbml", sep=""))
net <- loadSBML(paste(file,".sbml", sep=""))
saveNetwork(net, paste(file,".bnet", sep=""))
